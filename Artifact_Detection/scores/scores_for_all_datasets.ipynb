{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 Hz Binary:\n",
      "Accuracy score: 0.9100758396533044\n",
      "F1 Score: 0.8358763981937845\n"
     ]
    }
   ],
   "source": [
    "#*----------------------------------------------------------------------------*\n",
    "#* Copyright (C) 2024 ETH Zurich, Switzerland                                 *\n",
    "#* SPDX-License-Identifier: Apache-2.0                                        *\n",
    "#*                                                                            *\n",
    "#* Licensed under the Apache License, Version 2.0 (the \"License\");            *\n",
    "#* you may not use this file except in compliance with the License.           *\n",
    "#* You may obtain a copy of the License at                                    *\n",
    "#*                                                                            *\n",
    "#* http://www.apache.org/licenses/LICENSE-2.0                                 *\n",
    "#*                                                                            *\n",
    "#* Unless required by applicable law or agreed to in writing, software        *\n",
    "#* distributed under the License is distributed on an \"AS IS\" BASIS,          *\n",
    "#* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   *\n",
    "#* See the License for the specific language governing permissions and        *\n",
    "#* limitations under the License.                                             *\n",
    "#*                                                                            *\n",
    "#* Author:  Thorir Mar Ingolfsson                                             *\n",
    "#*----------------------------------------------------------------------------*\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "features = np.load('../data/x_train_250.npy')\n",
    "labels = np.load('../data/y_train_binary_250.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "\n",
    "# Average CV score on the training set was: 0.903792748162954\n",
    "exported_pipeline = ExtraTreesClassifier(bootstrap=True, criterion=\"gini\", max_features=0.15000000000000002, \n",
    "                                         min_samples_leaf=5, min_samples_split=3, n_estimators=100, n_jobs=-1)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250 Hz Binary:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thoriri/miniconda3/envs/TPOT/lib/python3.9/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 Hz MultiBinary:\n",
      "Accuracy score: 0.8798426450450609\n",
      "F1 Score: 0.4496729473786976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tpot.builtins import StackingEstimator\n",
    "from tpot.export_utils import set_param_recursive\n",
    "features = np.load('../data/x_train_250_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multi_binary_250_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.8798373679340494\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=DecisionTreeClassifier(criterion=\"gini\", max_depth=7, min_samples_leaf=9, \n",
    "                                                       min_samples_split=11)),\n",
    "    DecisionTreeClassifier(criterion=\"gini\", max_depth=10, min_samples_leaf=11, min_samples_split=13)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250 Hz MultiBinary:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 Hz MultiOutput:\n",
      "Accuracy score: 0.8716970564303623\n",
      "F1 Score: 0.8373526630506835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "features = np.load('../data/x_train_250_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multioutput_250_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.8718424598961854\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=MultinomialNB(alpha=1.0, fit_prior=False)),\n",
    "    DecisionTreeClassifier(criterion=\"gini\", max_depth=10, min_samples_leaf=13, min_samples_split=18)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250 Hz MultiOutput:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250Hz + 1000Hz Binary:\n",
      "Accuracy score: 0.8897879733599305\n",
      "F1 Score: 0.7975412985017288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "features = np.load('../data/x_train_250_1000.npy')\n",
    "labels = np.load('../data/y_train_binary_250_1000.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.8928981773960551\n",
    "exported_pipeline = make_pipeline(\n",
    "    SelectPercentile(score_func=f_classif, percentile=95),\n",
    "    MinMaxScaler(),\n",
    "    GradientBoostingClassifier(learning_rate=0.5, max_depth=7, max_features=0.05, min_samples_leaf=6, min_samples_split=4, n_estimators=100, subsample=0.8500000000000001)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250Hz + 1000Hz Binary:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250Hz + 1000Hz MultiBinary:\n",
      "Accuracy score: 0.880335399293927\n",
      "F1 Score: 0.45401740882718955\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "features = np.load('../data/x_train_250_1000_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multi_binary_250_1000_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.879984057844875\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=LogisticRegression(C=0.01, dual=False, penalty=\"l2\")),\n",
    "    DecisionTreeClassifier(criterion=\"gini\", max_depth=10, min_samples_leaf=4, min_samples_split=9)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250Hz + 1000Hz MultiBinary:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250Hz + 1000Hz MultiOutput:\n",
      "Accuracy score: 0.8720930062505301\n",
      "F1 Score: 0.8382886376735099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "features = np.load('../data/x_train_250_1000_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multioutput_250_1000_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.8718812037324135\n",
    "exported_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    DecisionTreeClassifier(criterion=\"gini\", max_depth=10, min_samples_leaf=9, min_samples_split=2)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250Hz + 1000Hz MultiOutput:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256Hz Binary:\n",
      "Accuracy score: 0.8432237585409157\n",
      "F1 Score: 0.8019303969548669\n"
     ]
    }
   ],
   "source": [
    "features = np.load('../data/x_train_256.npy')\n",
    "labels = np.load('../data/y_train_binary_256.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "\n",
    "# Average CV score on the training set was: 0.8345366502734926\n",
    "exported_pipeline = ExtraTreesClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.5, min_samples_leaf=5, min_samples_split=2, n_estimators=100, n_jobs=-1)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"256Hz Binary:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256Hz MultiBinary:\n",
      "Accuracy score: 0.8217033410448162\n",
      "F1 Score: 0.7691557536918362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "features = np.load('../data/x_train_256_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multi_binary_256_unrolled.npy')\n",
    "# Average CV score on the training set was: 0.8525547915406534\n",
    "exported_pipeline = KNeighborsClassifier(n_neighbors=41, p=1, weights=\"distance\")\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"256Hz MultiBinary:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256Hz MultiOutput:\n",
      "Accuracy score: 0.8441163667666062\n",
      "F1 Score: 0.7947964886031196\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "features = np.load('../data/x_train_256_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multioutput_256_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.8438450363093619\n",
    "exported_pipeline = KNeighborsClassifier(n_neighbors=25, p=1, weights=\"uniform\")\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"256Hz MultiOutput:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256Hz + 512Hz Binary:\n",
      "Accuracy score: 0.8413099484740388\n",
      "F1 Score: 0.8076853797658361\n",
      "256Hz + 512Hz MultiBinary:\n",
      "Accuracy score: 0.8185691636940151\n",
      "F1 Score: 0.7725183252577961\n",
      "256Hz + 512Hz MultiOutput:\n",
      "Accuracy score: 0.8334421843470741\n",
      "F1 Score: 0.7793764645849337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "features = np.load('../data/x_train_256_512.npy')\n",
    "labels = np.load('../data/y_train_binary_256_512.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "\n",
    "# Average CV score on the training set was: 0.8380404987178351\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=ExtraTreesClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.2, min_samples_leaf=3, min_samples_split=3, n_estimators=100)),\n",
    "    StackingEstimator(estimator=SGDClassifier(alpha=0.001, eta0=1.0, fit_intercept=False, l1_ratio=0.5, learning_rate=\"constant\", loss=\"squared_hinge\", penalty=\"elasticnet\", power_t=0.1)),\n",
    "    DecisionTreeClassifier(criterion=\"gini\", max_depth=6, min_samples_leaf=9, min_samples_split=17)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"256Hz + 512Hz Binary:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "\n",
    "\n",
    "features = np.load('../data/x_train_256_512_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multi_binary_256_512_unrolled.npy')\n",
    "# Average CV score on the training set was: 0.8435785268442461\n",
    "exported_pipeline = KNeighborsClassifier(n_neighbors=42, p=1, weights=\"distance\")\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "    \n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"256Hz + 512Hz MultiBinary:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "\n",
    "\n",
    "features = np.load('../data/x_train_256_512_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multioutput_256_512_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.8332207928593143\n",
    "exported_pipeline = make_pipeline(\n",
    "    VarianceThreshold(threshold=0.01),\n",
    "    KNeighborsClassifier(n_neighbors=39, p=1, weights=\"uniform\")\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"256Hz + 512Hz MultiOutput:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All frequencies Binary:\n",
      "Accuracy score: 0.8683960047711419\n",
      "F1 Score: 0.7862301113568312\n",
      "All frequencies MultiBinary:\n",
      "Accuracy score: 0.8543355944047518\n",
      "F1 Score: 0.7615760826694012\n",
      "All frequencies MultiOutput:\n",
      "Accuracy score: 0.8608604836982803\n",
      "F1 Score: 0.8235654043842016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_approximation import Nystroem\n",
    "from tpot.builtins import ZeroCount\n",
    "features = np.load('../data/x_train_all.npy')\n",
    "labels = np.load('../data/y_train_binary_all.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "\n",
    "# Average CV score on the training set was: 0.8642657669243821\n",
    "exported_pipeline = make_pipeline(\n",
    "    Nystroem(gamma=0.7000000000000001, kernel=\"linear\", n_components=7),\n",
    "    ExtraTreesClassifier(bootstrap=True, criterion=\"gini\", max_features=0.9000000000000001, min_samples_leaf=4, min_samples_split=4, n_estimators=100, n_jobs=-1)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"All frequencies Binary:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "\n",
    "\n",
    "features = np.load('../data/x_train_all_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multi_binary_all_unrolled.npy')\n",
    "# Average CV score on the training set was: 0.8725976631067676\n",
    "exported_pipeline = DecisionTreeClassifier(criterion=\"gini\", max_depth=10, min_samples_leaf=20, min_samples_split=9)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "    \n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"All frequencies MultiBinary:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "\n",
    "\n",
    "features = np.load('../data/x_train_all_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multioutput_all_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.8608947377109661\n",
    "exported_pipeline = make_pipeline(\n",
    "    ZeroCount(),\n",
    "    DecisionTreeClassifier(criterion=\"gini\", max_depth=10, min_samples_leaf=8, min_samples_split=5)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"All frequencies MultiOutput:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results, average='weighted')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 Hz Binary (Temporal):\n",
      "Accuracy score: 0.9394738118723824\n",
      "F1 Score: 0.8376631825475993\n",
      "250 Hz MultiBinary (Temporal):\n",
      "Accuracy score: 0.9005061407976973\n",
      "F1 Score: 0.5997235097991381\n",
      "250 Hz MultiOutput (Temporal):\n",
      "Accuracy score: 0.8922833741641805\n",
      "F1 Score: 0.8674482897267625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "features = np.load('../data/x_train_250_temporal.npy')\n",
    "labels = np.load('../data/y_train_binary_250_temporal.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "\n",
    "# Average CV score on the training set was: 0.9353538974885545\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=BernoulliNB(alpha=100.0, fit_prior=False)),\n",
    "    StackingEstimator(estimator=ExtraTreesClassifier(bootstrap=False, criterion=\"gini\", max_features=0.5, min_samples_leaf=2, min_samples_split=12, n_estimators=100)),\n",
    "    ExtraTreesClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.8, min_samples_leaf=5, min_samples_split=5, n_estimators=100)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250 Hz Binary (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "features = np.load('../data/x_train_250_temporal_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multi_binary_250_temporal_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.9001021630924988\n",
    "exported_pipeline = ExtraTreesClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.35000000000000003, min_samples_leaf=1, min_samples_split=4, n_estimators=100)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250 Hz MultiBinary (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "features = np.load('../data/x_train_250_temporal_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multioutput_250_temporal_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.8916159701788221\n",
    "exported_pipeline = ExtraTreesClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.8, min_samples_leaf=1, min_samples_split=11, n_estimators=100)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250 Hz MultiOutput (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thoriri/miniconda3/envs/TPOT/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 Hz Binary (Temporal):\n",
      "Accuracy score: 0.9363215937388829\n",
      "F1 Score: 0.8385668607034517\n",
      "250 Hz MultiBinary (Temporal):\n",
      "Accuracy score: 0.9297888166618156\n",
      "F1 Score: 0.8156576377685318\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "features = np.load('../data/x_train_250_temporal_2s.npy')\n",
    "labels = np.load('../data/y_train_binary_250_temporal_2s.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "\n",
    "# Average CV score on the training set was: 0.8866608946608945\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=ExtraTreesClassifier(bootstrap=False, criterion=\"gini\", max_features=0.5, min_samples_leaf=2, min_samples_split=12, n_estimators=100)),\n",
    "    XGBClassifier(learning_rate=0.5, max_depth=10, min_child_weight=17, n_estimators=100, n_jobs=1, subsample=1.0, verbosity=0)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250 Hz Binary (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "features = np.load('../data/x_train_250_temporal_2s_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multi_binary_250_temporal_2s_unrolled.npy')\n",
    "\n",
    "# Average CV score on the training set was: 0.8563970405945847\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=MultinomialNB(alpha=0.01, fit_prior=True)),\n",
    "    ExtraTreesClassifier(bootstrap=False, criterion=\"entropy\", max_features=1.0, min_samples_leaf=2, min_samples_split=16, n_estimators=100)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250 Hz MultiBinary (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250Hz + 1000Hz Binary (Temporal):\n",
      "Accuracy score: 0.9343167851742222\n",
      "F1 Score: 0.8247263361236317\n",
      "250Hz + 1000Hz MultiBinary (Temporal):\n",
      "Accuracy score: 0.901410829767382\n",
      "F1 Score: 0.607776\n",
      "250Hz + 1000Hz MultiOutput (Temporal):\n",
      "Accuracy score: 0.8924745021073968\n",
      "F1 Score: 0.8678263188915994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "features = np.load('../data/x_train_250_1000_temporal.npy')\n",
    "labels = np.load('../data/y_train_binary_250_1000_temporal.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.9338566227989687\n",
    "exported_pipeline = make_pipeline(\n",
    "    RobustScaler(),\n",
    "    StackingEstimator(estimator=ExtraTreesClassifier(bootstrap=False, criterion=\"gini\", max_features=0.45, min_samples_leaf=3, min_samples_split=20, n_estimators=100)),\n",
    "    ExtraTreesClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.9500000000000001, min_samples_leaf=9, min_samples_split=14, n_estimators=100)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250Hz + 1000Hz Binary (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "features = np.load('../data/x_train_250_1000_temporal_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multi_binary_250_1000_temporal_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.9008170970746223\n",
    "exported_pipeline = ExtraTreesClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.6000000000000001, min_samples_leaf=1, min_samples_split=15, n_estimators=100)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250Hz + 1000Hz MultiBinary (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "\n",
    "features = np.load('../data/x_train_250_1000_temporal_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multioutput_250_1000_temporal_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.8915623043411454\n",
    "exported_pipeline = ExtraTreesClassifier(bootstrap=True, criterion=\"gini\", max_features=0.55, min_samples_leaf=1, min_samples_split=7, n_estimators=100)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"250Hz + 1000Hz MultiOutput (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results, average='weighted')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256Hz Binary (Temporal):\n",
      "Accuracy score: 0.8734061440791951\n",
      "F1 Score: 0.6440780517319619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thoriri/miniconda3/envs/TPOT/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256Hz MultiBinary (Temporal):\n",
      "Accuracy score: 0.867541830311508\n",
      "F1 Score: 0.6067092651757188\n",
      "256Hz MultiOutput (Temporal):\n",
      "Accuracy score: 0.8692231129283908\n",
      "F1 Score: 0.8383738302151844\n"
     ]
    }
   ],
   "source": [
    "features = np.load('../data/x_train_256_temporal.npy')\n",
    "labels = np.load('../data/y_train_binary_256_temporal.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "\n",
    "\n",
    "# Average CV score on the training set was: 0.8729259174266039\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=ExtraTreesClassifier(bootstrap=False, criterion=\"gini\", max_features=0.6000000000000001, min_samples_leaf=2, min_samples_split=12, n_estimators=100)),\n",
    "    GradientBoostingClassifier(learning_rate=0.1, max_depth=7, max_features=0.2, min_samples_leaf=14, min_samples_split=15, n_estimators=100, subsample=0.8500000000000001)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"256Hz Binary (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "features = np.load('../data/x_train_256_temporal_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multi_binary_256_temporal_unrolled.npy')\n",
    "# Average CV score on the training set was: 0.880274417100841\n",
    "exported_pipeline = XGBClassifier(learning_rate=0.1, max_depth=10, min_child_weight=7, n_estimators=100, n_jobs=1, subsample=0.9000000000000001, verbosity=0)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"256Hz MultiBinary (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "features = np.load('../data/x_train_256_temporal_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multioutput_256_temporal_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.8688001974186669\n",
    "exported_pipeline = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),\n",
    "    VarianceThreshold(threshold=0.1),\n",
    "    ExtraTreesClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.2, min_samples_leaf=1, min_samples_split=12, n_estimators=100)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"256Hz MultiOutput (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256Hz + 512Hz Binary (Temporal):\n",
      "Accuracy score: 0.8688069758224336\n",
      "F1 Score: 0.6709741550695824\n",
      "256Hz + 512Hz MultiBinary (Temporal):\n",
      "Accuracy score: 0.8651902497027348\n",
      "F1 Score: 0.6467610022069324\n",
      "256Hz + 512Hz MultiOutput (Temporal):\n",
      "Accuracy score: 0.8568862794644073\n",
      "F1 Score: 0.8258367676075989\n"
     ]
    }
   ],
   "source": [
    "features = np.load('../data/x_train_256_512_temporal.npy')\n",
    "labels = np.load('../data/y_train_binary_256_512_temporal.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "\n",
    "# Average CV score on the training set was: 0.8668494119727651\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=ExtraTreesClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.7500000000000001, min_samples_leaf=4, min_samples_split=9, n_estimators=100)),\n",
    "    StandardScaler(),\n",
    "    ExtraTreesClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.7500000000000001, min_samples_leaf=6, min_samples_split=9, n_estimators=100)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"256Hz + 512Hz Binary (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "\n",
    "\n",
    "features = np.load('../data/x_train_256_512_temporal_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multi_binary_256_512_temporal_unrolled.npy')\n",
    "# Average CV score on the training set was: 0.8712535534621267\n",
    "exported_pipeline = ExtraTreesClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.8500000000000001, min_samples_leaf=1, min_samples_split=14, n_estimators=100)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "    \n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"256Hz + 512Hz MultiBinary (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "\n",
    "\n",
    "features = np.load('../data/x_train_256_512_temporal_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multioutput_256_512_temporal_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.8551558332411835\n",
    "exported_pipeline = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),\n",
    "    ExtraTreesClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.2, min_samples_leaf=1, min_samples_split=5, n_estimators=100)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"256Hz + 512Hz MultiOutput (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All frequencies Binary (Temporal):\n",
      "Accuracy score: 0.9222641236641406\n",
      "F1 Score: 0.7980088911151462\n",
      "All frequencies MultiBinary (Temporal):\n",
      "Accuracy score: 0.907239846263208\n",
      "F1 Score: 0.7487681514113232\n",
      "All frequencies MultiOutput:\n",
      "Accuracy score: 0.8794108345005196\n",
      "F1 Score: 0.8528066117658484\n"
     ]
    }
   ],
   "source": [
    "from tpot.builtins import OneHotEncoder\n",
    "features = np.load('../data/x_train_all_temporal.npy')\n",
    "labels = np.load('../data/y_train_binary_all_temporal.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "\n",
    "# Average CV score on the training set was: 0.9185302377742959\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=ExtraTreesClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.8, min_samples_leaf=3, min_samples_split=6, n_estimators=100)),\n",
    "    DecisionTreeClassifier(criterion=\"entropy\", max_depth=7, min_samples_leaf=14, min_samples_split=8)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"All frequencies Binary (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "\n",
    "\n",
    "features = np.load('../data/x_train_all_temporal_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multi_binary_all_temporal_unrolled.npy')\n",
    "# Average CV score on the training set was: 0.8939939812444007\n",
    "exported_pipeline = KNeighborsClassifier(n_neighbors=63, p=1, weights=\"distance\")\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "    \n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"All frequencies MultiBinary (Temporal):\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results)))\n",
    "\n",
    "\n",
    "\n",
    "features = np.load('../data/x_train_all_temporal_unrolled.npy')\n",
    "labels = np.load('../data/y_train_multioutput_all_temporal_unrolled.npy')\n",
    "\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, labels, random_state=42)\n",
    "# Average CV score on the training set was: 0.8785453866190636\n",
    "exported_pipeline = make_pipeline(\n",
    "    OneHotEncoder(minimum_fraction=0.2, sparse=False, threshold=10),\n",
    "    KNeighborsClassifier(n_neighbors=41, p=1, weights=\"distance\")\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(\"All frequencies MultiOutput:\")\n",
    "print(\"Accuracy score: \" + str(accuracy_score(testing_target,results)))\n",
    "print(\"F1 Score: \" + str(f1_score(testing_target,results, average='weighted')))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c78ae76ff2fb2bb774457ce33403107aee201f761c281eb8b84cebc14202b6bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
